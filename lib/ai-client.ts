// lib/ai-client.ts
/**
 * AI Client for Entropy Reverse Project
 * Supports: Custom AI API (OpenAI-compatible) or Alibaba Cloud Qwen
 */

// æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è‡ªå®šä¹‰AIæ¥å£
const useCustomAI = !!process.env.AI_BASE_URL && !!process.env.AI_API_KEY;

// è‡ªå®šä¹‰AIé…ç½®
const AI_BASE_URL = process.env.AI_BASE_URL;
const AI_API_KEY = process.env.AI_API_KEY;
const AI_MODEL_VISION = process.env.AI_MODEL_VISION || 'gpt-4-vision-preview';
const AI_MODEL_TEXT = process.env.AI_MODEL_TEXT || 'gpt-4';

// é˜¿é‡Œäº‘é€šä¹‰åƒé—®é…ç½®
const DASHSCOPE_API_KEY = process.env.DASHSCOPE_API_KEY;
const DASHSCOPE_BASE_URL = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation';
const DASHSCOPE_TEXT_URL = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation';

// éªŒè¯é…ç½®ï¼ˆå»¶è¿Ÿåˆ°è¿è¡Œæ—¶ï¼‰
function validateConfig() {
  if (!useCustomAI && !DASHSCOPE_API_KEY) {
    throw new Error('Please configure either custom AI (AI_BASE_URL + AI_API_KEY) or DASHSCOPE_API_KEY');
  }
}

/**
 * è°ƒç”¨è‡ªå®šä¹‰AIè§†è§‰æ¨¡å‹ï¼ˆOpenAIå…¼å®¹æ ¼å¼ï¼‰
 */
async function callCustomVision(imageBase64: string, prompt: string): Promise<string> {
  const response = await fetch(`${AI_BASE_URL}/chat/completions`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${AI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: AI_MODEL_VISION,
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: prompt },
            { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${imageBase64}` } }
          ]
        }
      ],
      max_tokens: 1000,
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Custom AI API error: ${response.status} - ${errorText}`);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

/**
 * è°ƒç”¨è‡ªå®šä¹‰AIæ–‡æœ¬æ¨¡å‹ï¼ˆOpenAIå…¼å®¹æ ¼å¼ï¼‰
 */
async function callCustomText(prompt: string): Promise<string> {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 90000); // 90ç§’è¶…æ—¶

  try {
    const response = await fetch(`${AI_BASE_URL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${AI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: AI_MODEL_TEXT,
        messages: [
          { role: 'system', content: 'You are a helpful assistant that returns responses in JSON format.' },
          { role: 'user', content: prompt }
        ],
        temperature: 0.8,
        max_tokens: 2000,
      }),
      signal: controller.signal
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Custom AI API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  } catch (error: any) {
    clearTimeout(timeoutId);
    if (error.name === 'AbortError') {
      throw new Error('AI API request timeout (90s)');
    }
    throw error;
  }
}

/**
 * è°ƒç”¨é€šä¹‰åƒé—®è§†è§‰æ¨¡å‹
 */
async function callQwenVision(imageBase64: string, prompt: string): Promise<string> {
  const response = await fetch(DASHSCOPE_BASE_URL, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${DASHSCOPE_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'qwen-vl-plus',
      input: {
        messages: [
          {
            role: 'user',
            content: [
              { text: prompt },
              { image: `data:image/jpeg;base64,${imageBase64}` }
            ]
          }
        ]
      },
      parameters: {
        result_format: 'message'
      }
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Qwen API error: ${response.status} - ${errorText}`);
  }

  const data = await response.json();

  if (data.output?.choices?.[0]?.message?.content?.[0]?.text) {
    return data.output.choices[0].message.content[0].text;
  }

  throw new Error('Invalid response format from Qwen API');
}

/**
 * è°ƒç”¨é€šä¹‰åƒé—®æ–‡æœ¬æ¨¡å‹
 */
async function callQwenText(prompt: string): Promise<string> {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 90000); // 90ç§’è¶…æ—¶

  try {
    const response = await fetch(DASHSCOPE_TEXT_URL, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${DASHSCOPE_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'qwen-plus',
        input: {
          messages: [
            {
              role: 'system',
              content: 'You are a helpful assistant that returns responses in JSON format.'
            },
            {
              role: 'user',
              content: prompt
            }
          ]
        },
        parameters: {
          result_format: 'message',
          temperature: 0.8
        }
      }),
      signal: controller.signal
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Qwen API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();

    if (data.output?.choices?.[0]?.message?.content) {
      return data.output.choices[0].message.content;
    }

    throw new Error('Invalid response format from Qwen API');
  } catch (error: any) {
    clearTimeout(timeoutId);
    if (error.name === 'AbortError') {
      throw new Error('Qwen API request timeout (90s)');
    }
    throw error;
  }
}

/**
 * ç»Ÿä¸€çš„è§†è§‰APIè°ƒç”¨æ¥å£
 */
export async function callVisionAPI(imageBase64: string, prompt: string): Promise<string> {
  validateConfig();
  if (useCustomAI) {
    console.log('Using custom AI vision model:', AI_MODEL_VISION);
    return callCustomVision(imageBase64, prompt);
  } else {
    console.log('Using Qwen vision model');
    return callQwenVision(imageBase64, prompt);
  }
}

/**
 * ç»Ÿä¸€çš„æ–‡æœ¬APIè°ƒç”¨æ¥å£
 */
export async function callTextAPI(prompt: string): Promise<string> {
  validateConfig();
  if (useCustomAI) {
    console.log('Using custom AI text model:', AI_MODEL_TEXT);
    return callCustomText(prompt);
  } else {
    console.log('Using Qwen text model');
    return callQwenText(prompt);
  }
}

/**
 * System prompt for image identification
 */
export const IDENTIFICATION_PROMPT = `è¯†åˆ«å›¾ç‰‡ä¸­çš„ä¸»è¦ç‰©ä½“ï¼Œè¿”å›JSONæ ¼å¼ï¼ˆä¸­æ–‡ï¼‰ï¼š

{
  "name": "å…·ä½“åç§°ï¼ˆå¦‚'iPhone 15 Pro'è€Œé'æ‰‹æœº'ï¼‰",
  "category": "ç±»åˆ«ï¼ˆå¦‚'ç”µå­äº§å“'ã€'äº¤é€šå·¥å…·'ã€'å®¶å…·'ï¼‰",
  "brief_description": "å®¢è§‚æè¿°ï¼ˆ2-3å¥è¯ï¼ŒåŒ…å«ææ–™ã€åŠŸèƒ½ï¼‰"
}

è¦æ±‚ï¼šå‡†ç¡®ã€å…·ä½“ã€å®¢è§‚ï¼Œä½¿ç”¨ä¸“ä¸šä¸­æ–‡ã€‚`;

/**
 * Generate system prompt for deconstruction
 * @param currentItem - The item to deconstruct
 * @param parentContext - Optional parent context for better understanding
 */
export function getDeconstructionPrompt(currentItem: string, parentContext?: string): string {
  const contextNote = parentContext ? `\nContext: This item is part of "${parentContext}".` : '';

  return `Role: You are a manufacturing and materials expert analyzing product composition and supply chains.

Task: Break down "${currentItem}" into its constituent components or materials (one level only).${contextNote}

CRITICAL CONSTRAINTS:
1. Maximum decomposition depth: 6 levels total
2. Final leaf nodes MUST be from the Basic Elements List below
3. Be LESS detailed - skip minor components, focus on major materials
4. When close to basic elements, jump directly to them (don't over-decompose)

BASIC ELEMENTS LIST (Final Leaf Nodes MUST be from this list):
ğŸŒ¿ Organic/Biological:
- Wood (æœ¨æ)
- Cotton/Fiber (æ£‰/æ¤ç‰©çº¤ç»´)
- Natural Rubber (å¤©ç„¶æ©¡èƒ¶)
- Biomass (ç”Ÿç‰©è´¨/é£Ÿç‰©)

ğŸ›¢ï¸ Fossil/Chemical:
- Crude Oil (åŸæ²¹)
- Coal (ç…¤ç‚­)

ğŸ’ Minerals/Metals:
- Iron Ore (é“çŸ¿çŸ³)
- Copper Ore (é“œçŸ¿çŸ³)
- Bauxite (é“åœŸçŸ¿)
- Silica Sand (ç¡…ç ‚/çŸ³è‹±)
- Gold (é‡‘)
- Lithium (é”‚)

ğŸ’§ Basic Elements:
- Water (æ°´)
- Clay/Stone (é»åœŸ/çŸ³å¤´)

DECOMPOSITION STRATEGY (Maximum 6 levels):

Level 1 - ASSEMBLED PRODUCTS:
â†’ Break into 3-5 major functional components only
â†’ Example: "Smartphone" â†’ Display, Battery, Circuit board, Housing

Level 2-3 - MAJOR COMPONENTS:
â†’ Break into main material types (skip minor parts)
â†’ Example: "Display" â†’ Glass, Plastic frame, Metal connectors

Level 4-5 - MATERIALS:
â†’ Identify the material category
â†’ Example: "Glass" â†’ Silica Sand, Soda ash (from Clay/Stone)
â†’ Example: "Plastic" â†’ Crude Oil

Level 6 - BASIC ELEMENTS:
â†’ MUST be from the Basic Elements List above
â†’ Mark is_raw_material = true

IMPORTANT RULES:
1. Use Chinese for all names and descriptions (ä¸­æ–‡è¾“å‡º)
2. Be LESS precise - combine similar materials, skip minor components
3. When you reach a material that's 1-2 steps from basic elements, jump directly
4. NEVER exceed 6 levels of decomposition
5. Final nodes MUST match the Basic Elements List exactly
6. Skip chemical synthesis steps - go straight to basic elements

EXAMPLES:

âœ“ "å¡‘æ–™ç“¶" â†’ å¡‘æ–™ â†’ åŸæ²¹ (2 levels, good!)
âœ“ "ç»ç’ƒçª—" â†’ ç»ç’ƒ â†’ ç¡…ç ‚ (2 levels, good!)
âœ“ "é’¢æ¶" â†’ é’¢æ â†’ é“çŸ¿çŸ³, ç…¤ç‚­ (2 levels, good!)
âœ“ "ç”µè·¯æ¿" â†’ PCBåŸºæ¿, é“œçº¿, ç„Šæ–™ â†’ (next level: ç¡…ç ‚, é“œçŸ¿çŸ³, etc.)

âŒ "å¡‘æ–™ç“¶" â†’ èšä¹™çƒ¯æ ‘è„‚ â†’ èšåˆç‰©é¢—ç²’ â†’ ç²¾ç‚¼çŸ³æ²¹ â†’ åŸæ²¹ (TOO DETAILED!)

Output Format: JSON only (Chinese names and descriptions).
{
  "parent_item": "${currentItem}",
  "parts": [
    {
      "name": "ç»„ä»¶æˆ–ææ–™åç§°ï¼ˆä¸­æ–‡ï¼‰",
      "description": "åŠŸèƒ½æˆ–ç‰¹æ€§ï¼ˆä¸­æ–‡ï¼‰",
      "is_raw_material": true or false
    }
  ]
}`;
}
